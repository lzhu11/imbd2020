{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Input_A1_001</th>\n",
       "      <th>Input_A1_002</th>\n",
       "      <th>Input_A1_003</th>\n",
       "      <th>Input_A1_004</th>\n",
       "      <th>Input_A1_005</th>\n",
       "      <th>Input_A1_006</th>\n",
       "      <th>Input_A1_007</th>\n",
       "      <th>Input_A1_008</th>\n",
       "      <th>Input_A1_009</th>\n",
       "      <th>...</th>\n",
       "      <th>Input_C_134</th>\n",
       "      <th>Input_C_135</th>\n",
       "      <th>Input_C_136</th>\n",
       "      <th>Input_C_137</th>\n",
       "      <th>Output_A1</th>\n",
       "      <th>Output_A2</th>\n",
       "      <th>Output_A3</th>\n",
       "      <th>Output_A4</th>\n",
       "      <th>Output_A5</th>\n",
       "      <th>Output_A6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.004</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.202</td>\n",
       "      <td>4.280</td>\n",
       "      <td>2.804</td>\n",
       "      <td>4.805</td>\n",
       "      <td>3.178</td>\n",
       "      <td>2.888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.303</td>\n",
       "      <td>4.113</td>\n",
       "      <td>2.949</td>\n",
       "      <td>3.073</td>\n",
       "      <td>3.539</td>\n",
       "      <td>4.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.078</td>\n",
       "      <td>3.672</td>\n",
       "      <td>4.303</td>\n",
       "      <td>4.508</td>\n",
       "      <td>3.734</td>\n",
       "      <td>3.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Test4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.816</td>\n",
       "      <td>3.928</td>\n",
       "      <td>2.827</td>\n",
       "      <td>3.098</td>\n",
       "      <td>3.616</td>\n",
       "      <td>3.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Test5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.015</td>\n",
       "      <td>3.672</td>\n",
       "      <td>4.514</td>\n",
       "      <td>4.165</td>\n",
       "      <td>3.856</td>\n",
       "      <td>3.494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Test91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.201</td>\n",
       "      <td>3.300</td>\n",
       "      <td>4.069</td>\n",
       "      <td>3.265</td>\n",
       "      <td>3.602</td>\n",
       "      <td>3.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Test92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.050</td>\n",
       "      <td>3.502</td>\n",
       "      <td>3.252</td>\n",
       "      <td>3.169</td>\n",
       "      <td>3.689</td>\n",
       "      <td>3.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Test93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.561</td>\n",
       "      <td>3.739</td>\n",
       "      <td>3.243</td>\n",
       "      <td>3.779</td>\n",
       "      <td>3.113</td>\n",
       "      <td>3.592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Test94</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.004</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.863</td>\n",
       "      <td>3.962</td>\n",
       "      <td>3.145</td>\n",
       "      <td>3.212</td>\n",
       "      <td>3.156</td>\n",
       "      <td>3.647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Test95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.021</td>\n",
       "      <td>3.604</td>\n",
       "      <td>3.480</td>\n",
       "      <td>3.106</td>\n",
       "      <td>3.908</td>\n",
       "      <td>3.114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 268 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number  Input_A1_001  Input_A1_002  Input_A1_003  Input_A1_004  \\\n",
       "0    Test1          0.00          0.00          0.00          0.00   \n",
       "1    Test2          0.00          0.00          0.00          0.00   \n",
       "2    Test3          0.00          0.00          0.00          0.00   \n",
       "3    Test4          0.00          0.00          0.02          0.04   \n",
       "4    Test5          0.00          0.00          0.00          0.00   \n",
       "..     ...           ...           ...           ...           ...   \n",
       "90  Test91          0.00          0.00          0.00          0.00   \n",
       "91  Test92          0.00          0.00          0.02          0.04   \n",
       "92  Test93          0.00          0.00          0.00          0.00   \n",
       "93  Test94          0.08          0.06          0.03          0.00   \n",
       "94  Test95          0.00          0.00          0.00          0.00   \n",
       "\n",
       "    Input_A1_005  Input_A1_006  Input_A1_007  Input_A1_008  Input_A1_009  ...  \\\n",
       "0           0.00         0.002         0.004         0.002         0.004  ...   \n",
       "1           0.00         0.016         0.004         0.002         0.004  ...   \n",
       "2           0.00         0.006         0.006         0.002         0.002  ...   \n",
       "3           0.07         0.004         0.005         0.002         0.005  ...   \n",
       "4           0.00         0.012         0.008         0.002         0.003  ...   \n",
       "..           ...           ...           ...           ...           ...  ...   \n",
       "90          0.00         0.014         0.014         0.002         0.004  ...   \n",
       "91          0.09         0.010         0.004         0.002         0.004  ...   \n",
       "92          0.00         0.014         0.014         0.002         0.005  ...   \n",
       "93          0.00         0.006         0.010         0.002         0.004  ...   \n",
       "94          0.00         0.008         0.014         0.002         0.004  ...   \n",
       "\n",
       "    Input_C_134  Input_C_135  Input_C_136  Input_C_137  Output_A1  Output_A2  \\\n",
       "0        -0.004         4.00          1.0          1.0      3.202      4.280   \n",
       "1         0.003         4.00          1.0          1.0      4.303      4.113   \n",
       "2        -0.003         3.70          1.0          1.0      4.078      3.672   \n",
       "3         0.004         4.00          0.0          0.0      3.816      3.928   \n",
       "4         0.004         4.00          1.0          1.0      4.015      3.672   \n",
       "..          ...          ...          ...          ...        ...        ...   \n",
       "90        0.005         0.04          1.0          3.0      4.201      3.300   \n",
       "91        0.004         0.04          1.0          2.0      3.050      3.502   \n",
       "92        0.004         0.04          2.0          2.0      3.561      3.739   \n",
       "93       -0.005         0.04          2.0          2.0      2.863      3.962   \n",
       "94        0.006         0.04          2.0          2.0      3.021      3.604   \n",
       "\n",
       "    Output_A3  Output_A4  Output_A5  Output_A6  \n",
       "0       2.804      4.805      3.178      2.888  \n",
       "1       2.949      3.073      3.539      4.187  \n",
       "2       4.303      4.508      3.734      3.013  \n",
       "3       2.827      3.098      3.616      3.018  \n",
       "4       4.514      4.165      3.856      3.494  \n",
       "..        ...        ...        ...        ...  \n",
       "90      4.069      3.265      3.602      3.921  \n",
       "91      3.252      3.169      3.689      3.909  \n",
       "92      3.243      3.779      3.113      3.592  \n",
       "93      3.145      3.212      3.156      3.647  \n",
       "94      3.480      3.106      3.908      3.114  \n",
       "\n",
       "[95 rows x 268 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np  #數學庫\n",
    "from sklearn.model_selection import train_test_split #隨機劃分訓練＆測試集\n",
    "from sklearn.linear_model import LinearRegression #簡單線性迴歸\n",
    "from sklearn.preprocessing import PolynomialFeatures #多項式回歸\n",
    "import matplotlib.pyplot as plt #繪圖\n",
    "import tensorflow.compat.v1 as tf #機器學習的開發平台\n",
    "tf.compat.v1.disable_eager_execution() #我安裝的是v2所以要轉成v1\n",
    "\n",
    "#取得資料\n",
    "dataset = pd.read_csv(r'0728test.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#將數據標準化\n",
    "def standardize(x):\n",
    "    mean_x = x.mean(axis=0) #計算數據x每個特徵的均值\n",
    "    std_x = x.std(axis=0) #計算數據x每個特徵的方差\n",
    "    return (x - mean_x)/std_x #標準化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,1:96] #基於索引值先行後列 \n",
    "y = dataset['Output_A1']\n",
    "X_std=standardize(X)\n",
    "y_std=standardize(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#將資料分為訓練＆測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_std, y_std, test_size=0.4, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001 #學習率，需要根據最後的曲線做調整:https://www.itread01.com/content/1548936569.html\n",
    "epochs = 1000 #一個完整的資料集通過了神經網路一次並且返回了一次，這個過程稱為一次epoch\n",
    "#file_writer_path = \"./graphs/regression\"\n",
    "loss_history = [] #to save the loss value at each epoch\n",
    "batch_size = 20 #決定我們一次訓練的樣本數目:https://codertw.com/程式語言/557816/\n",
    "n_obs = X_train.shape[0] #https://stackoverflow.com/questions/48134598/x-shape0-vs-x0-shape-in-numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#創建tf計算圖形\n",
    "with tf.name_scope(\"placeholders\"): #對於每個變量賦予不同名字\n",
    "    X = tf.placeholder(tf.float32)#宣告 placeholder 張量的資料型態（tf.float32）\n",
    "    y = tf.placeholder(tf.float32)\n",
    "\n",
    "with tf.name_scope(\"variables\"):\n",
    "    W = tf.Variable(tf.random_normal((95, 1))) #Variable定義圖變量,random_normal生成符合正態分佈的矩陣,總之就是宣告 Variable 張量外觀為 (95, 1) ，並隨機給予初始值。\n",
    "\n",
    "with tf.name_scope(\"prediction\"): #計算圖形上撰寫預測值的計算公式\n",
    "    y_pred = tf.matmul(X, W) #placeholder 張量與 Variable 張量內積\n",
    "\n",
    "with tf.name_scope(\"loss\"): #損失函數 MSE\n",
    "    loss = tf.reduce_mean(tf.pow(tf.subtract(y, y_pred), 2))#subtract:y-y_pred,pow:subtract出來的值＊2,mean為求平均\n",
    "                       \n",
    "with tf.name_scope(\"optimizer\"): #指定最適化的演算法梯度遞減以及所搭配的學習速率\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 91.26393127441406\n",
      "epoch: 100, loss: 56.884090423583984\n",
      "epoch: 200, loss: 39.647464752197266\n",
      "epoch: 300, loss: 29.673524856567383\n",
      "epoch: 400, loss: 23.218721389770508\n",
      "epoch: 500, loss: 18.722339630126953\n",
      "epoch: 600, loss: 15.445778846740723\n",
      "epoch: 700, loss: 12.989360809326172\n",
      "epoch: 800, loss: 11.111001968383789\n",
      "epoch: 900, loss: 9.652068138122559\n",
      "[[ 0.17648348]\n",
      " [-0.16896884]\n",
      " [ 0.10741871]\n",
      " [-0.03076633]\n",
      " [ 0.2973485 ]\n",
      " [ 0.39015555]\n",
      " [-1.7806313 ]\n",
      " [ 0.02457917]\n",
      " [ 0.33073986]\n",
      " [-0.5535267 ]\n",
      " [-0.5538279 ]\n",
      " [ 0.74453336]\n",
      " [ 0.6729168 ]\n",
      " [ 0.5372386 ]\n",
      " [-0.25127545]\n",
      " [-0.2087802 ]\n",
      " [-1.6302834 ]\n",
      " [ 1.9833939 ]\n",
      " [-0.77899605]\n",
      " [ 0.71846193]\n",
      " [ 0.4150342 ]\n",
      " [-0.25613394]\n",
      " [-0.5970896 ]\n",
      " [ 0.74428505]\n",
      " [-1.138364  ]\n",
      " [-0.25633186]\n",
      " [ 0.54346985]\n",
      " [-0.31574738]\n",
      " [ 0.9276757 ]\n",
      " [-0.7059997 ]\n",
      " [-1.1736641 ]\n",
      " [ 1.3689758 ]\n",
      " [ 0.15408175]\n",
      " [ 0.10055587]\n",
      " [-0.38495073]\n",
      " [-0.34913528]\n",
      " [ 0.12839258]\n",
      " [-0.490103  ]\n",
      " [-0.43033776]\n",
      " [ 0.65899664]\n",
      " [ 0.67621154]\n",
      " [ 0.2168677 ]\n",
      " [-0.5283279 ]\n",
      " [ 1.0048743 ]\n",
      " [ 1.037651  ]\n",
      " [-0.0337969 ]\n",
      " [-1.4031849 ]\n",
      " [ 0.9699895 ]\n",
      " [ 0.46000782]\n",
      " [-0.9302629 ]\n",
      " [-0.7008561 ]\n",
      " [-0.15508117]\n",
      " [ 0.89861125]\n",
      " [-0.14932431]\n",
      " [-0.12965964]\n",
      " [-0.10177487]\n",
      " [-0.9075036 ]\n",
      " [-0.17558372]\n",
      " [-0.26988074]\n",
      " [-1.672061  ]\n",
      " [ 1.6028216 ]\n",
      " [-2.0138936 ]\n",
      " [-0.10891208]\n",
      " [ 1.2046244 ]\n",
      " [-1.564356  ]\n",
      " [ 0.4370281 ]\n",
      " [-0.38457316]\n",
      " [ 0.8607878 ]\n",
      " [ 1.1714076 ]\n",
      " [ 0.10031844]\n",
      " [ 1.2964351 ]\n",
      " [-0.71254975]\n",
      " [ 1.1578313 ]\n",
      " [ 0.02379119]\n",
      " [-0.7451694 ]\n",
      " [-1.2169331 ]\n",
      " [-1.2078961 ]\n",
      " [ 0.23056315]\n",
      " [-0.03227371]\n",
      " [ 0.6820884 ]\n",
      " [-0.7331421 ]\n",
      " [-0.04382443]\n",
      " [ 0.22561507]\n",
      " [-0.02301027]\n",
      " [ 1.0910047 ]\n",
      " [-0.21587478]\n",
      " [-0.09851287]\n",
      " [-0.7613032 ]\n",
      " [-0.12369329]\n",
      " [-0.17573166]\n",
      " [-1.2009798 ]\n",
      " [ 0.8592979 ]\n",
      " [ 0.8146077 ]\n",
      " [ 1.6161356 ]\n",
      " [ 0.13299422]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess: #利用 tf.Session() 啟動創建好的計算圖形進行訓練\n",
    "    sess.run(tf.global_variables_initializer()) # 初始化所有的變數張量\n",
    "    #train_writer = tf.summary.FileWriter(file_writer_path, tf.get_default_graph())\n",
    "    for i in range(epochs):\n",
    "        pos = 0\n",
    "        while pos < n_obs:\n",
    "            X_train_batch = X_train.iloc[pos:(pos + batch_size), :]\n",
    "            y_train_batch = y_train.iloc[pos:(pos + batch_size)]\n",
    "            training_data = {\n",
    "                X: X_train_batch,\n",
    "                y: y_train_batch\n",
    "            }\n",
    "            _, _loss = sess.run([optimizer, loss], feed_dict=training_data) #在命名上記得做出區隔\n",
    "            pos += batch_size\n",
    "        loss_history.append(_loss) #將損失記錄起來\n",
    "        if i % 100 == 0:\n",
    "            print(\"epoch: {}, loss: {}\".format(i, _loss))\n",
    "    W_final = sess.run(W)\n",
    "print(W_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#將每一輪訓練所記錄的損失 loss_history 繪畫出來觀察收斂的狀況\n",
    "plt.plot(loss_history)\n",
    "plt.title(\"Loss History\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.669808957495313\n"
     ]
    }
   ],
   "source": [
    "#預測與評估\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_mean = y_test.mean()\n",
    "y_std = y_test.std()\n",
    "y_pred_std = np.dot(X_test, W_final)\n",
    "y_pred = y_pred_std * y_std + y_mean\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
